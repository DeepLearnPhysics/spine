# Base configuration
base:
  world_size: 0
  iterations: 10
  seed: 0
  unwrap: false
  log_dir: .
  log_step: 1
  overwrite_log: true
  train:
    weight_prefix: snapshot
    save_step: 10
    optimizer:
      name: Adam
      lr: 0.001

# IO configuration
io:
  loader:
    batch_size: 2
    shuffle: false
    num_workers: 0
    collate_fn: all
    sampler:
      name: random_sequence
      seed: 0
    dataset:
      name: larcv
      file_keys: null
      schema:
        data:
          parser: cluster3d
          cluster_event: cluster3d_pcluster
          particle_event: particle_corrected
          sparse_semantics_event: sparse3d_pcluster_semantics
          add_particle_info: true
          clean_data: true
          break_clusters: true
        coord_label:
          parser: particle_coords
          particle_event: particle_corrected
          cluster_event: cluster3d_pcluster

# Model configuration
model:
  name: grappa
  weight_path: null

  network_input:
    data: data
    coord_label: coord_label
  loss_input:
    clust_label: data

  modules:
    grappa:
      nodes:
        source: cluster
        shapes: [shower, michel, delta]
        min_size: -1
        make_groups: true
        grouping_method: score
      graph:
        name: complete
        max_length: [500, 0, 500, 500, 0, 0, 0, 25, 0, 25]
        dist_algorithm: recursive
      node_encoder:
        name: geo
        use_numpy: true
        add_value: true
        add_shape: true
        add_points: true
        add_local_dirs: true
        dir_max_dist: 5
        add_local_dedxs: true
        dedx_max_dist: 5
      edge_encoder:
        name: geo
        use_numpy: true
      gnn_model:
        name: meta
        node_feats: 33 # 16 (geo) + 3 (extra) + 6 (points) + 6 (directions) + 2 (local dedxs)
        edge_feats: 19
        node_pred: 2
        edge_pred: 2
        edge_layer:
          name: mlp
          mlp:
            depth: 3
            width: 64
            activation:
              name: lrelu
              negative_slope: 0.1
            normalization: batch_norm
        node_layer:
          name: mlp
          reduction: max
          attention: false
          message_mlp:
            depth: 3
            width: 64
            activation:
              name: lrelu
              negative_slope: 0.1
            normalization: batch_norm
          aggr_mlp:
            depth: 3
            width: 64
            activation:
              name: lrelu
              negative_slope: 0.1
            normalization: batch_norm

    grappa_loss:
      node_loss:
        name: shower_primary
        high_purity: true
        use_group_pred: true
      edge_loss:
        name: channel
        target: group
        high_purity: true
